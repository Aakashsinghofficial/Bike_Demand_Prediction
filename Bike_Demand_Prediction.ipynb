import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor


def load_and_prepare(path="hour.csv"):
    # Load
    df = pd.read_csv(path)

    # Basic cleanup
    df['dteday'] = pd.to_datetime(df['dteday'])
    if {'casual', 'registered'}.issubset(df.columns):
        df = df.drop(['casual', 'registered'], axis=1)

    # Date-based features
    df['year'] = df['dteday'].dt.year
    df['month'] = df['dteday'].dt.month
    df['day'] = df['dteday'].dt.day
    df['weekday'] = df['dteday'].dt.weekday
    df = df.drop('dteday', axis=1)

    # Cyclic encoding of hour
    df['hr_sin'] = np.sin(2 * np.pi * df['hr'] / 24)
    df['hr_cos'] = np.cos(2 * np.pi * df['hr'] / 24)
    df = df.drop('hr', axis=1)

    # Avoid multicollinearity: drop atemp if present (it is highly correlated to temp)
    if 'atemp' in df.columns:
        df = df.drop('atemp', axis=1)

    # Interaction / derived features
    if {'weathersit', 'workingday'}.issubset(df.columns):
        df['bad_weather_workday'] = ((df['weathersit'] > 2) & (df['workingday'] == 1)).astype(int)
    if {'temp', 'season'}.issubset(df.columns):
        df['temp_season_interaction'] = df['temp'] * df['season']

    # Optional target transform kept separately if needed
    df['cnt_log'] = np.log1p(df['cnt'])

    # Time-series lag / rolling features
    for lag in [1, 2, 3, 24, 48, 168]:
        df[f'cnt_lag_{lag}'] = df['cnt'].shift(lag)

    df['rolling_mean_24'] = df['cnt'].shift(1).rolling(24).mean()
    df['rolling_std_24'] = df['cnt'].shift(1).rolling(24).std()

    # Drop rows with NaNs introduced by lags/rolling
    df = df.dropna().reset_index(drop=True)

    return df


def train_and_evaluate(df):
    X = df.drop(['cnt', 'cnt_log'], axis=1)
    y = df['cnt']

    # Keep time ordering (no shuffle)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    print(f"Train shape: {X_train.shape}, Test shape: {X_test.shape}")

    # Linear Regression
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    y_pred_lr = lr.predict(X_test)

    # Random Forest
    rf = RandomForestRegressor(n_estimators=300, max_depth=15, min_samples_split=5, random_state=42, n_jobs=-1)
    rf.fit(X_train, y_train)
    y_pred_rf = rf.predict(X_test)

    # Gradient Boosting
    gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42)
    gb.fit(X_train, y_train)
    y_pred_gb = gb.predict(X_test)

    # Evaluate
    results = []
    for name, y_pred in [
        ('Linear Regression', y_pred_lr),
        ('Random Forest', y_pred_rf),
        ('Gradient Boosting', y_pred_gb),
    ]:
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        results.append({'Model': name, 'RMSE': rmse, 'R2': r2})

    results_df = pd.DataFrame(results).sort_values('RMSE')
    print(results_df.to_string(index=False))

    # Feature importances from RF
    importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
    print("\nTop 15 feature importances (Random Forest):")
    print(importances.head(15).to_string())

    # Residual analysis for the best model (Gradient Boosting assumed best here)
    residuals = y_test - y_pred_gb
    plt.figure(figsize=(8, 5))
    plt.scatter(y_pred_gb, residuals, alpha=0.4)
    plt.axhline(0, color='red')
    plt.xlabel("Predicted Demand")
    plt.ylabel("Residuals")
    plt.title("Residual Analysis (Gradient Boosting)")
    plt.tight_layout()
    plt.show()

    # MAPE
    mape = np.mean(np.abs((y_test - y_pred_gb) / y_test)) * 100
    print(f"\nMAPE (Gradient Boosting): {mape:.2f}%")

    return {
        "models": {"lr": lr, "rf": rf, "gb": gb},
        "results_df": results_df,
        "feature_importances": importances,
        "X_test": X_test,
        "y_test": y_test,
        "y_pred_gb": y_pred_gb,
    }


def main(csv_path="hour.csv"):
    df = load_and_prepare(csv_path)
    out = train_and_evaluate(df)
    # Optionally return trained models / results
    return out


if __name__ == "__main__":
    # Change the path below if your CSV is in a different location
    main("hour.csv")
